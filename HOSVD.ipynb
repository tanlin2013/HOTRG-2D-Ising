{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial of HOTRG algorithm with python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook aims at providing the detailed explanations on how HOTRG works, with the step-by-step constructions. The code is organized into 3 classes:\n",
    "\n",
    "* HOTRG\n",
    "* XY\n",
    "* Ising\n",
    "\n",
    "where the main algorithm is written in HOTRG class. While XY and Ising classes are 2 examples which demonstrate how to compute the physical quantities through this method.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "The main ideal of this alrorithm is based on the real space renormalization group (RG) procedure. \n",
    "\n",
    "In TRG language, the partition function is regarded as the tensor network. In partipular, for the 2-dimensional classical models, the tensor network is formed by the 4-legs tensor, $T_{l_i,r_i,u_i,d_i}$, which is living on each site of the 2D lattice. \n",
    "\n",
    "At each step of RG iterations, we would coarse grain 4 tensors as a cell into a new tensor. The procedure is taken by first contracting the X direction, then contract the Y direction. For example,\n",
    "\n",
    "$$ M_{l,r,u,d}^{(n)} = \\sum_i T_{l_1,r_1,u,i}^{(n)} T_{l_2,r_2,i,d}^{(n)}$$ where $l=l_1 \\otimes l_2$ and $r=r_1 \\otimes r_2$.\n",
    "\n",
    "However, the bond dimensions, i.e. the number of indexes on the corresponding axis of tensor, would grow after we contract 2 tensors together. For instance, the $l$ and $r$ axes at the above equation have doubled thier bond dimensions. Therefore, we would perform the higher-order SVD (HOSVD) to truncate the bond dimensions.\n",
    "\n",
    "$$T_{l',r',u,d}^{(n+1)}=\\sum_{l,r} U_{l,l'}^{(n)}M_{l,r,u,d}^{(n)}U_{r,r'}^{(n)}$$ where $U^{(n)}$ is determined by the HOSVD.\n",
    "\n",
    "Also, in practice, the amplitude of every tensor elements could go large (or small) after few RG iterations. Therefore, in order to keep it within the digit allowed in computers, we would normalize the tensor with its norm at each RG step. Also, these norms have to be stored in a histogram. We would add them back to the partition functions in the end of the calculations.\n",
    "\n",
    "### 1.1 Ordering of the tensor $T$\n",
    "In this note, the ordering of the tensor is counted counterclockwise. Namely,\n",
    "\n",
    "<br>\n",
    "<center> \n",
    "0 \n",
    "<br>\n",
    "|\n",
    "<br>\n",
    "1--T--3\n",
    "<br>\n",
    "|\n",
    "<br>\n",
    "2 \n",
    "</center>\n",
    "\n",
    "### 1.2 The oder after the tensor contraction\n",
    "The way how python count the order after the tensor contraction is by first counting the axes of the first tensor with its original order, then count the second tensor with its orginal order. For example, if we are connecting bond 3 of tensor $A$ with bond 1 of tensor $B$\n",
    "\n",
    "<br>\n",
    "<center> \n",
    "0 \n",
    "<br>\n",
    "|\n",
    "<br>\n",
    "1--A--3\n",
    "<br>\n",
    "|\n",
    "<br>\n",
    "2 \n",
    "</center>\n",
    "and\n",
    "<br>\n",
    "<center> \n",
    "0 \n",
    "<br>\n",
    "|\n",
    "<br>\n",
    "1--B--3\n",
    "<br>\n",
    "|\n",
    "<br>\n",
    "2 \n",
    "</center>\n",
    "\n",
    "The resulting tensor is\n",
    "\n",
    "<br>\n",
    "<center> \n",
    "0 3\n",
    "<br>\n",
    "||\n",
    "<br>\n",
    "1--AB--5\n",
    "<br>\n",
    "||\n",
    "<br>\n",
    "2 4\n",
    "</center>\n",
    "\n",
    "Therefore, in order to keep the order being correctly in the way that we count the order counterclockwise. We would need to swap the axes. For example, for the above tensor, we need to swap:\n",
    "\n",
    "$$1 \\leftrightarrow 3$$\n",
    "$$2 \\leftrightarrow 3$$\n",
    "$$0 \\leftrightarrow 1$$\n",
    "\n",
    "which leads to\n",
    "\n",
    "<br>\n",
    "<center> \n",
    "1 0\n",
    "<br>\n",
    "||\n",
    "<br>\n",
    "2--AB--5\n",
    "<br>\n",
    "||\n",
    "<br>\n",
    "3 4\n",
    "</center>\n",
    "\n",
    "then you can reshape it into a rank-4 tensor\n",
    "\n",
    "<br>\n",
    "<center> \n",
    "0\n",
    "<br>\n",
    "||\n",
    "<br>\n",
    "1--AB--3\n",
    "<br>\n",
    "||\n",
    "<br>\n",
    "2\n",
    "</center>\n",
    "\n",
    "\n",
    "### 1.3 References\n",
    "Please also refer the following references:\n",
    "\n",
    "[Ref.1 - Coarse-graining renormalization by higher-order singular value decomposition](https://journals.aps.org/prb/abstract/10.1103/PhysRevB.86.045139)\n",
    "\n",
    "[Ref.2 - Tensor renormalization group study of classical XY model on the square lattice](https://arxiv.org/abs/1309.4963)\n",
    "\n",
    "[Ref.3 - Tensor network algorithm by coarse-graining tensor renormalization on finite periodic lattices](https://arxiv.org/abs/1510.03333)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import packages\n",
    "Packages which are used in this code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from itertools import product\n",
    "from scipy.special import iv\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Class HOTRG\n",
    "In this section, we would provide the detail explanations on the algorithm itself. There are 4 functions contained in this class:\n",
    "\n",
    "* \\__init\\__(self,T0,D,maxstep)\n",
    "* _HOSVD(self,M,chi,axes)\n",
    "* T_norm(self,T)\n",
    "* RG(self)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 \\__init\\__(self,T0,D,maxstep)\n",
    "Constructor of HOTRG class. \n",
    "\n",
    "* Arguments:\n",
    "\n",
    "    * T0: ndarray <br>\n",
    "        An initaial tensor for the RG iterations. The shape of this tensor is $(D,D,D,D)$.          \n",
    "    * D: int     \n",
    "        The bond dimensions.\n",
    "    * maxstep: int  <br> \n",
    "        Maximum number of RG iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class HOTRG:\n",
    "    def __init__(self,T0,D,maxstep):\n",
    "        self._init_tensor=T0\n",
    "        self.D=D\n",
    "        self.maxstep=maxstep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 _HOSVD(self,M,chi,axes)\n",
    "Performing the higher-order SVD to the tensor $M$,\n",
    "\n",
    "$$ M_{xx'yy'}^{(n)} = \\sum_{ijkl} S_{ijkl}U_{xi}^{L}U_{x'j}^{R}U_{yk}^{U}U_{y'l}^{D} $$\n",
    "\n",
    "However, since we only need $U^L$ or $U^R$, only these two would be computed.\n",
    "\n",
    "* Arguments:\n",
    "\n",
    "    * M: ndarray <br>\n",
    "        The tensor that you want to perform the HOSVD. The shape of this tensor is either $(D^2,D,D^2,D)$ or $(D,D^2,D,D^2)$.\n",
    "    * chi: int <br>\n",
    "        The bond dimensions to keep, which is D here.\n",
    "    * axes: tuple(int,int) <br>\n",
    "        The 2 axes that you want to perform the truncation via HOSVD.\n",
    "    \n",
    "* Returns:\n",
    "\n",
    "    * U: ndarray <br>\n",
    "        The left singular matrix with shape $(D^2,D)$.\n",
    "        \n",
    "<div class=\"alert alert-warning\">\n",
    "<b>NOTE</b> This function has already customized for the HOTRG algorithm, and is not suitable for the general situations.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    def _HOSVD(self,M,chi,axes):\n",
    "        Us=[]; Ss=[]\n",
    "        for n in axes:\n",
    "            A=np.copy(M)\n",
    "            if n>0:\n",
    "                for roll in xrange(4-n):\n",
    "                    A=np.rollaxis(A,-1)\n",
    "            A=np.ndarray.reshape(A,(A.shape[0],int(A.size/A.shape[0])))\n",
    "            x,s,y=np.linalg.svd(A,full_matrices=False) \n",
    "            Us.append(x); Ss.append(s)\n",
    "            \n",
    "        epsilon1=np.sum(np.square(np.delete(Ss[0],np.arange(chi))))\n",
    "        epsilon2=np.sum(np.square(np.delete(Ss[1],np.arange(chi))))\n",
    "        if epsilon1 < epsilon2:\n",
    "            U=Us[0][:,0:chi]\n",
    "        else:\n",
    "            U=Us[1][:,0:chi]\n",
    "        return U"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function can be seperated into 2 parts, with first compute the ordinary SVD on the 2 given axes, then perform the truncation by comparing the magnitude of $\\epsilon_1$ and $\\epsilon_2$, which are given by\n",
    "\n",
    "$$ \\epsilon_1 = \\sum_{i>D} |S_{i,:,:,:}|^2 $$\n",
    "and\n",
    "$$ \\epsilon_2 = \\sum_{j>D} |S_{:,j,:,:}|^2 $$\n",
    "\n",
    "They are basically the trucation error on the correponding axis, and we just choose to truncate the smaller one. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 T_norm(self,T)\n",
    "Compute the norm of tensor $T$.\n",
    "\n",
    "* Arguments:\n",
    "\n",
    "    * T: ndarray <br>\n",
    "        The tensor $T$ of which the shape is $(D,D,D,D)$.\n",
    "        \n",
    "* Returns:\n",
    "\n",
    "    * norm: float <br>\n",
    "        The norm of tensor $T$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    def T_norm(self,T):\n",
    "        norm=np.linalg.norm(np.ndarray.reshape(T,(self.D**2,self.D**2)))\n",
    "        if np.isinf(norm) or norm<=0.0: raise ValueError('T_norm is {}'.format(norm))\n",
    "        return norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 RG(self)\n",
    "The main algorithm which performs the RG coarse graining procedure to tensor $T$.\n",
    "\n",
    "* Returns:\n",
    "\n",
    "    * T: ndarray <br>\n",
    "        The tensor after maxstep of RG coarse graining.\n",
    "    \n",
    "    * norm_histo: list[float] <br>\n",
    "        A list which stores all the normalization factors during the RG iterations.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    def RG(self):\n",
    "        norm_histo=[] \n",
    "        T=self._init_tensor \n",
    "        for step in xrange(1,maxstep+1):\n",
    "            print \"RG step {}\".format(step)\n",
    "            # X direction\n",
    "            M=np.tensordot(T,T,axes=(3,1))\n",
    "            M=np.swapaxes(M,1,3)\n",
    "            M=np.swapaxes(M,2,3)\n",
    "            M=np.swapaxes(M,0,1)\n",
    "            M=np.ndarray.reshape(M,(self.D**2,self.D,self.D**2,self.D))\n",
    "            U=self._HOSVD(M,chi=self.D,axes=(0,2))                \n",
    "            T=np.tensordot(np.tensordot(M,U,axes=(0,0)),U,axes=(1,0))\n",
    "            T=np.swapaxes(T,0,2)\n",
    "            T=np.swapaxes(T,1,2)\n",
    "            T=np.swapaxes(T,2,3)\n",
    "            # Y direction\n",
    "            M=np.tensordot(T,T,axes=(2,0))\n",
    "            M=np.swapaxes(M,3,4)\n",
    "            M=np.swapaxes(M,2,4)\n",
    "            M=np.swapaxes(M,4,5)\n",
    "            M=np.ndarray.reshape(M,(self.D,self.D**2,self.D,self.D**2))\n",
    "            U=self._HOSVD(M,chi=self.D,axes=(1,3))\n",
    "            T=np.tensordot(np.tensordot(M,U,axes=(1,0)),U,axes=(2,0))\n",
    "            T=np.swapaxes(T,1,2)                \n",
    "            # normalized factor\n",
    "            norm=self.T_norm(T)\n",
    "            norm_histo.append(norm)\n",
    "            T/=norm\n",
    "        return T,norm_histo  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The coarse graining is performed first along the X axis. However, the bond dimensions on the Y direction is expanded from $D$ to $D^2$. Thus, we performed the HOSVD, and truncated these 2 bonds to dimensions $D$. The same procedure is taken for Y direction, then we would normalize the tensor $T$ with its norm due to the allowed numerical digits. These norms will be pushed back into the partion functions in the end of the calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Class XY\n",
    "There are 5 functions contained in this class:\n",
    "\n",
    "* \\__init\\__(self,betas,h,D,maxstep)\n",
    "\n",
    "* _init_tensor(self,beta)\n",
    "\n",
    "* build_parti_func(self)\n",
    "\n",
    "* free_energy(self,lnZs)\n",
    "\n",
    "* energy(self,lnZs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 __init__(self,betas,h,D,maxstep)\n",
    "Constructor of XY class.\n",
    "\n",
    "* Arguments:\n",
    "\n",
    "    * betas: array <br>\n",
    "        An array which stores the range of inverse temperature.\n",
    "    * h: float <br>\n",
    "        The strength of external magnetic field of the XY model.\n",
    "    * D: int <br>\n",
    "        The bond dimensions.\n",
    "    * maxstep: int <br>\n",
    "        Maximum number of RG iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class XY:\n",
    "    def __init__(self,betas,h,D,maxstep):\n",
    "        self.betas=betas\n",
    "        self.h=h\n",
    "        self.D=D\n",
    "        self.maxstep=maxstep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 _init_tensor(self,beta)\n",
    "Creating the initial tensor $T$ of the XY model.\n",
    "\n",
    "$$ T_{l,r,u,d} = \\sqrt{I_l(\\beta)I_r(\\beta)I_u(\\beta)I_d(\\beta)} \\, I_{l+r-u-d}(\\beta h) $$\n",
    "\n",
    "* Arguments:\n",
    "\n",
    "    * beta: float <br>\n",
    "        The inverse temperature.\n",
    "\n",
    "* Returns：\n",
    "\n",
    "    * T: ndarray <br>\n",
    "        The tensor $T$ of the XY model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    def _init_tensor(self,beta):\n",
    "        T=np.zeros((self.D,self.D,self.D,self.D),dtype=float)\n",
    "        for i,j,k,l in product(range(self.D),repeat=4):\n",
    "            T[i,j,k,l]=np.sqrt(iv(i,beta)*iv(j,beta)*iv(k,beta)*iv(l,beta)) * iv(i+j-k-l,beta*self.h)\n",
    "        T=np.swapaxes(T,1,2)\n",
    "        return T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 build_parti_func(self)\n",
    "Compute the value of partion function from self.betas. In other words, this function returns the partition function as a function of inverse temperature.\n",
    "\n",
    "* Returns:\n",
    "\n",
    "    * lnZs: array <br>\n",
    "        The logarithm of partition function as a function of inverse temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    def build_parti_func(self):\n",
    "        lnZs=[]\n",
    "        for beta in self.betas:\n",
    "            print \"sim XY - beta= {}, h={}, D={}, maxstep={}\".format(beta,self.h,self.D,self.maxstep)\n",
    "            T0=self._init_tensor(beta)\n",
    "            sim=HOTRG(T0,self.D,self.maxstep)\n",
    "            T,norm_histo=sim.RG()\n",
    "            lnZ=(np.sum(np.log(norm_histo)/np.logspace(1,self.maxstep,base=4,num=self.maxstep)) \n",
    "                    + np.log(sim.T_norm(T))/(4**self.maxstep))\n",
    "            lnZs.append(lnZ)\n",
    "        return np.array(lnZs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, the norm of tensor T from each RG step is pushed back here by using the formula:\n",
    "\n",
    "$$ \\ln Z = \\sum_{n=1}^{N} \\frac{1}{4^n}\\ln \\lambda_n + \\frac{\\ln \\lambda_{N}}{4^{N}} $$\n",
    "\n",
    "where $\\lambda_N$ is the norm of tensor $T$ after $N$ steps of RG iterations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 free_energy(self,lnZs)\n",
    "Compute the free energy by using the formula:\n",
    "\n",
    "$$ F = - \\frac{1}{\\beta} \\ln Z$$\n",
    "\n",
    "* Arguments:\n",
    "\n",
    "    * lnZs: array <br>\n",
    "    \n",
    "* Returns: \n",
    "\n",
    "    * F: array <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    def free_energy(self,lnZs):\n",
    "        F=-lnZs/self.betas\n",
    "        return F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 energy(self,lnZs)\n",
    "Compute the average (internal) energy by using the formula:\n",
    "\n",
    "$$ E = - \\frac{\\partial}{\\partial \\beta} \\ln Z $$\n",
    "\n",
    "* Arguments:\n",
    "\n",
    "    * lnZs: array\n",
    "\n",
    "* Returns:\n",
    "\n",
    "    * E: array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    def energy(self,lnZs):\n",
    "        E=-np.diff(lnZs)/np.diff(self.betas)\n",
    "        return E"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Class Ising\n",
    "There are 5 functions contained in this class:\n",
    "\n",
    "* \\__init\\__(self,betas,maxstep)\n",
    "\n",
    "* _init_tensor(self,beta)\n",
    "\n",
    "* build_parti_func(self)\n",
    "\n",
    "* free_energy(self,lnZs)\n",
    "\n",
    "* energy(self,lnZs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 __init__(self,betas,maxstep)\n",
    "Constructor of Ising class. Note that $D$ is 2 by default.\n",
    "\n",
    "* Arguments:\n",
    "\n",
    "    * betas: array <br>\n",
    "        An array which stores the range of inverse temperature.\n",
    "    * maxstep: int <br>\n",
    "        Maximum number of RG iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Ising:\n",
    "    def __init__(self,betas,maxstep):\n",
    "        self.betas=betas\n",
    "        self.D=2\n",
    "        self.maxstep=maxstep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 _init_tensor(self,beta)\n",
    "Creating the initial tensor $T$ of the Ising model.\n",
    "\n",
    "$$ T_{l,r,u,d} =  \\sum_{\\alpha} W_{\\alpha,l}W_{\\alpha,r}W_{\\alpha,u}W_{\\alpha,d} $$\n",
    "\n",
    "where $W$ is a $2 \\times 2$ matrix defined by\n",
    "\n",
    "$$ W = \\begin{pmatrix}\n",
    "       \\sqrt{\\cosh(\\beta)} & \\sqrt{\\sinh(\\beta)} \\\\\n",
    "       \\sqrt{\\cosh(\\beta)} & -\\sqrt{\\sinh(\\beta)} \\\\\n",
    "       \\end{pmatrix}$$\n",
    "\n",
    "* Arguments:\n",
    "\n",
    "    * beta: float <br>\n",
    "        The inverse temperature.\n",
    "\n",
    "* Returns：\n",
    "\n",
    "    * T: ndarray <br>\n",
    "        The tensor $T$ of the Ising model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    def _init_tensor(self,beta):\n",
    "        T=np.zeros((self.D,self.D,self.D,self.D),dtype=float)\n",
    "        W=np.array([[np.sqrt(np.cosh(beta)),np.sqrt(np.sinh(beta))],\n",
    "                     [np.sqrt(np.cosh(beta)),-np.sqrt(np.sinh(beta))]])\n",
    "        for i,j,k,l in product(range(self.D),repeat=4):\n",
    "            T[i,j,k,l]=np.sum(W[:,i]*W[:,j]*W[:,k]*W[:,l])\n",
    "        return T   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 build_parti_func(self)\n",
    "Compute the value of partion function from self.betas. In other words, this function returns the partition function as a function of inverse temperature.\n",
    "\n",
    "* Returns:\n",
    "\n",
    "    * lnZs: array <br>\n",
    "        The logarithm of partition function as a function of inverse temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    def build_parti_func(self):\n",
    "        lnZs=[]\n",
    "        for beta in self.betas:\n",
    "            print \"sim XY - beta= {}, D={}, maxstep={}\".format(beta,self.D,self.maxstep)\n",
    "            T0=self._init_tensor(beta)\n",
    "            sim=HOTRG(T0,self.D,self.maxstep)\n",
    "            T,norm_histo=sim.RG()\n",
    "            lnZ=(np.sum(np.log(norm_histo)/np.logspace(1,self.maxstep,base=4,num=self.maxstep)) \n",
    "                    + np.log(sim.T_norm(T))/(4**self.maxstep))\n",
    "            lnZs.append(lnZ)\n",
    "        return np.array(lnZs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, the norm of tensor T from each RG step is pushed back here by using the formula:\n",
    "\n",
    "$$ \\ln Z = \\sum_{n=1}^{N} \\frac{1}{4^n}\\ln \\lambda_n + \\frac{\\ln \\lambda_{N}}{4^{N}} $$\n",
    "\n",
    "where $\\lambda_N$ is the norm of tensor $T$ after $N$ steps of RG iterations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 free_energy(self,lnZs)\n",
    "Compute the free energy by using the formula:\n",
    "\n",
    "$$ F = - \\frac{1}{\\beta} \\ln Z$$\n",
    "\n",
    "* Arguments:\n",
    "\n",
    "    * lnZs: array <br>\n",
    "    \n",
    "* Returns: \n",
    "\n",
    "    * F: array <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    def free_energy(self,lnZs):\n",
    "        F=-lnZs/self.betas\n",
    "        return F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 energy(self,lnZs)\n",
    "Compute the average (internal) energy by using the formula:\n",
    "\n",
    "$$ E = - \\frac{\\partial}{\\partial \\beta} \\ln Z $$\n",
    "\n",
    "* Arguments:\n",
    "\n",
    "    * lnZs: array\n",
    "\n",
    "* Returns:\n",
    "\n",
    "    * E: array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    def energy(self,lnZs):\n",
    "        E=-np.diff(lnZs)/np.diff(self.betas)\n",
    "        return E"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Main code\n",
    "Plot the free energy $F$ and the average energy $E$ as a function of temperature $T$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "XY instance has no attribute 'build_parti_func'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-112-c8e9333da302>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m#model=Ising(betas,maxstep)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mXY\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbetas\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmaxstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mlnZs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_parti_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mF\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfree_energy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlnZs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mE\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menergy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlnZs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: XY instance has no attribute 'build_parti_func'"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':  \n",
    "    \n",
    "    Ts=np.linspace(0.1,2.0,30)\n",
    "    betas=1./Ts\n",
    "    h=0.0\n",
    "    D=10\n",
    "    maxstep=10\n",
    "    \n",
    "    #model=Ising(betas,maxstep)\n",
    "    model=XY(betas,h,D,maxstep)\n",
    "    lnZs=model.build_parti_func()\n",
    "    F=model.free_energy(lnZs)\n",
    "    E=model.energy(lnZs)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(Ts,F,linestyle=\"-\",marker=\"o\")\n",
    "    plt.plot(Ts[:-1],E,linestyle=\"-\",marker=\"o\")\n",
    "    plt.xlabel('T')\n",
    "    plt.legend(('F/N','E/N'),loc=2,numpoints=1)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
